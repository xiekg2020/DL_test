{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZrVT3tHIad9n3BYHCR0WO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiekg2020/DL_test/blob/main/7_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK0KJyFfNq8k"
      },
      "source": [
        "import tensorflow as tf\n",
        "!pip install d2l\n",
        "from d2l import tensorflow as d2l\n",
        "\n",
        "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps):\n",
        "    # Compute reciprocal of square root of the moving variance elementwise\n",
        "    inv = tf.cast(tf.math.rsqrt(moving_var + eps), X.dtype)\n",
        "    # Scale and shift\n",
        "    inv *= gamma\n",
        "    Y = X * inv + (beta - moving_mean * inv)\n",
        "    return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWPRQ-8TNy_w"
      },
      "source": [
        "class BatchNorm(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(BatchNorm, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        weight_shape = [input_shape[-1],]\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = self.add_weight(name='gamma', shape=weight_shape,\n",
        "                                     initializer=tf.initializers.ones,\n",
        "                                     trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=weight_shape,\n",
        "                                    initializer=tf.initializers.zeros,\n",
        "                                    trainable=True)\n",
        "        # The variables that are not model parameters are initialized to 0\n",
        "        self.moving_mean = self.add_weight(name='moving_mean',\n",
        "                                           shape=weight_shape,\n",
        "                                           initializer=tf.initializers.zeros,\n",
        "                                           trainable=False)\n",
        "        self.moving_variance = self.add_weight(\n",
        "            name='moving_variance', shape=weight_shape,\n",
        "            initializer=tf.initializers.ones, trainable=False)\n",
        "        super(BatchNorm, self).build(input_shape)\n",
        "\n",
        "    def assign_moving_average(self, variable, value):\n",
        "        momentum = 0.9\n",
        "        delta = variable * momentum + value * (1 - momentum)\n",
        "        return variable.assign(delta)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs, training):\n",
        "        if training:\n",
        "            axes = list(range(len(inputs.shape) - 1))\n",
        "            batch_mean = tf.reduce_mean(inputs, axes, keepdims=True)\n",
        "            batch_variance = tf.reduce_mean(\n",
        "                tf.math.squared_difference(inputs,\n",
        "                                           tf.stop_gradient(batch_mean)),\n",
        "                axes, keepdims=True)\n",
        "            batch_mean = tf.squeeze(batch_mean, axes)\n",
        "            batch_variance = tf.squeeze(batch_variance, axes)\n",
        "            mean_update = self.assign_moving_average(self.moving_mean,\n",
        "                                                     batch_mean)\n",
        "            variance_update = self.assign_moving_average(\n",
        "                self.moving_variance, batch_variance)\n",
        "            self.add_update(mean_update)\n",
        "            self.add_update(variance_update)\n",
        "            mean, variance = batch_mean, batch_variance\n",
        "        else:\n",
        "            mean, variance = self.moving_mean, self.moving_variance\n",
        "        output = batch_norm(inputs, moving_mean=mean, moving_var=variance,\n",
        "                            beta=self.beta, gamma=self.gamma, eps=1e-5)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8CuldTFN9Rj"
      },
      "source": [
        "# Recall that this has to be a function that will be passed to `d2l.train_ch6`\n",
        "# so that model building or compiling need to be within `strategy.scope()` in\n",
        "# order to utilize the CPU/GPU devices that we have\n",
        "def net():\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=6, kernel_size=5,\n",
        "                               input_shape=(28, 28, 1)),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Conv2D(filters=16, kernel_size=5),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(120),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(84),\n",
        "        BatchNorm(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(10)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVi1vcbXODEC"
      },
      "source": [
        "lr, num_epochs, batch_size = 1.0, 10, 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
        "net = d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu_uLK02OLKN"
      },
      "source": [
        "tf.reshape(net.layers[1].gamma, (-1,)), tf.reshape(net.layers[1].beta, (-1,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diGvs9dxOPhU"
      },
      "source": [
        "def net():\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=6, kernel_size=5,\n",
        "                               input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Conv2D(filters=16, kernel_size=5),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(120),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(84),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Activation('sigmoid'),\n",
        "        tf.keras.layers.Dense(10),])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4e1kqXKOS8R"
      },
      "source": [
        "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}