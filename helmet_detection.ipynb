{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "helmet_detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOG4mvUb4QUloZiMdYrbfNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiekg2020/DL_test/blob/main/helmet_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udzISIXhi-FG"
      },
      "source": [
        "# **Make sure you're using TensorFlow 1.15:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94_6cd7biZKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d23f8a-c78f-47a3-d91a-63fd1b154cd7"
      },
      "source": [
        "try:\n",
        "  # This %tensorflow_version magic only works in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "# For your non-Colab code, be sure you have tensorflow==1.15\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUXHxyz3jDoI"
      },
      "source": [
        "# **Build the TF1 Object Detection API:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNWCtC8MizMX",
        "outputId": "e76cf3b3-5df2-43cc-b15b-e7cdf718881d"
      },
      "source": [
        "! pip install tf_slim\n",
        "! git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtcAwTw4iz8t"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/'\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/slim/'\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/object_detection/utils/'\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/object_detection'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I7bXvKRjPj-",
        "outputId": "c6b38b44-ef56-446a-a9be-efb836ae6aed"
      },
      "source": [
        "! apt-get install protobuf-compiler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 97 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXoGNGLxjU_t",
        "outputId": "d812149d-4ce6-4c05-950e-298ac4d1ba89"
      },
      "source": [
        "%cd models/research\n",
        "# Compile all the protobuf dependencies\n",
        "! protoc object_detection/protos/*.proto --python_out=.\n",
        "# Set up and install the object detection API\n",
        "! cp object_detection/packages/tf1/setup.py .\n",
        "! python -m pip install .\n",
        "# Run a test to make sure setup is correct\n",
        "! python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "Processing /content/models/research\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (57.0.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2018.9)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1658050 sha256=f2587e17a5e5f027130caacd038be5ec7fdeecf038988b9bc075bb21685577d3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ctl1pmzs/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5_adi1xjbjG"
      },
      "source": [
        "# **Prepare dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8I8k_UAjeoP",
        "outputId": "1f05e8b0-2d13-4f09-e94f-b585e8c7c4c3"
      },
      "source": [
        "%mkdir /content/dataset\n",
        "%cd /content/dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/dataset’: File exists\n",
            "/content/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5teDhKEkMsB",
        "outputId": "932b2dd2-5b1e-40bc-83b1-1a90473efe41"
      },
      "source": [
        "from google.colab import files\n",
        "local_files=files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-07 06:32:57--  https://public.roboflow.com/ds/VUqgNE4eF7?key=jWeiF3tUqx\n",
            "Resolving public.roboflow.com (public.roboflow.com)... 151.101.65.195, 151.101.1.195\n",
            "Connecting to public.roboflow.com (public.roboflow.com)|151.101.65.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/roboflow-platform-exports/Ly2DeBzbwsemGd2ReHk4BFxy8683/TlE7G4GXJk3kU7ivmTPR/2/tfrecord.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=roboflow-platform%40appspot.gserviceaccount.com%2F20210707%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210707T063258Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=b58a911127612a2828ac9bb97000b69a22bc2b6f050846959dbe515b01be1a6ed9f17d9bdf8badda88d2f38851eeb4eaeeb51756b490d7f13d2fbc005dbe739cd722f4367aa142b753d9054c589e2d5b68c4a2bc4c673419e123c2257bdbfeefd671acf420119e25a32850e534880ec19bffd5dc1a9b9695cd0f11e172a588f90599b359dac0c2644079caac0c29c6caa135a2f76541cc79bf9adcf46f0c5a3bd4a55c9053ef099b0c42d15b6bc82a04390860caba6a5d58f7d23168c15dbd57205b5639f41e8316adc936cf86d216bf77e88021f140decbc28f8618394f2a5b31708ad38ae26edae7828413d1e96bf4e515e8889b1c147a73da3693cf3ac262 [following]\n",
            "--2021-07-07 06:32:59--  https://storage.googleapis.com/roboflow-platform-exports/Ly2DeBzbwsemGd2ReHk4BFxy8683/TlE7G4GXJk3kU7ivmTPR/2/tfrecord.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=roboflow-platform%40appspot.gserviceaccount.com%2F20210707%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210707T063258Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=b58a911127612a2828ac9bb97000b69a22bc2b6f050846959dbe515b01be1a6ed9f17d9bdf8badda88d2f38851eeb4eaeeb51756b490d7f13d2fbc005dbe739cd722f4367aa142b753d9054c589e2d5b68c4a2bc4c673419e123c2257bdbfeefd671acf420119e25a32850e534880ec19bffd5dc1a9b9695cd0f11e172a588f90599b359dac0c2644079caac0c29c6caa135a2f76541cc79bf9adcf46f0c5a3bd4a55c9053ef099b0c42d15b6bc82a04390860caba6a5d58f7d23168c15dbd57205b5639f41e8316adc936cf86d216bf77e88021f140decbc28f8618394f2a5b31708ad38ae26edae7828413d1e96bf4e515e8889b1c147a73da3693cf3ac262\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.128, 142.250.141.128, 2607:f8b0:4023:c0b::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 244284985 (233M) [application/zip]\n",
            "Saving to: ‘VUqgNE4eF7?key=jWeiF3tUqx’\n",
            "\n",
            "VUqgNE4eF7?key=jWei 100%[===================>] 232.97M   118MB/s    in 2.0s    \n",
            "\n",
            "2021-07-07 06:33:01 (118 MB/s) - ‘VUqgNE4eF7?key=jWeiF3tUqx’ saved [244284985/244284985]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYCEWV2fmnzO",
        "outputId": "9d02abfd-99bf-44e5-8ca5-397c2b9c5e94"
      },
      "source": [
        "! unzip -o Hard_Hat_Workers.v2-raw.tfrecord.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Hard_Hat_Workers.v2-raw.tfrecord.zip\n",
            " extracting: test/Workers.tfrecord   \n",
            " extracting: train/Workers.tfrecord  \n",
            " extracting: test/Workers_label_map.pbtxt  \n",
            " extracting: train/Workers_label_map.pbtxt  \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: README.dataset.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecWFmhazpw_-"
      },
      "source": [
        "# **Prepare the model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oOlennVpjGT",
        "outputId": "f8746176-1787-4424-dd77-e3cd933ee505"
      },
      "source": [
        "!mkdir /content/pretrained_model\n",
        "%cd /content/pretrained_model\n",
        "! wget http://download.tensorflow.org/models/object_detection/ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19.tar.gz\n",
        "! tar xvf ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19.tar.gz\n",
        "\n",
        "PIPELINE_CONFIG_PATH = '/content/models/research/object_detection/samples/configs/ssdlite_mobiledet_edgetpu_320x320_coco_sync_4x4.config'\n",
        "PIPELINE_CHECKPOINT_PATH = '/content/pretrained_model/ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/model.ckpt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/pretrained_model’: File exists\n",
            "/content/pretrained_model\n",
            "--2021-07-07 06:33:08--  http://download.tensorflow.org/models/object_detection/ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.2.128, 2607:f8b0:4023:c0d::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.2.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 156413934 (149M) [application/x-tar]\n",
            "Saving to: ‘ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19.tar.gz.1’\n",
            "\n",
            "ssdlite_mobiledet_e 100%[===================>] 149.17M   247MB/s    in 0.6s    \n",
            "\n",
            "2021-07-07 06:33:09 (247 MB/s) - ‘ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19.tar.gz.1’ saved [156413934/156413934]\n",
            "\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/model.ckpt-400000.data-00000-of-00001\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/model.ckpt-400000.index\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/model.ckpt-400000.meta\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/tflite_graph.pbtxt\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/tflite_graph.pb\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/pipeline.config\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/model.tflite\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/uint8/\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/uint8/model.ckpt-400000.data-00000-of-00001\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/uint8/model.ckpt-400000.index\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/uint8/model.ckpt-400000.meta\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/uint8/tflite_graph.pbtxt\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/uint8/tflite_graph.pb\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/uint8/pipeline.config\n",
            "ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/uint8/model.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAt1xs4BH1dM"
      },
      "source": [
        "# Ideally, we'd use more steps, but much larger will reach the system timeout for a free Colab environment\n",
        "# If you have Colab Pro or you're running offline, try 25000\n",
        "NUM_STEPS = 8000\n",
        "\n",
        "# Ideally, batch size would be larger, but smaller is necessary to avoid OOM Killer on free Colab environments\n",
        "# If you have Colab Pro or you're running offline, try 64\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# For this tutorial, we're training just two classes\n",
        "# If you train with the whole cats/dogs dataset, it's 37 classes\n",
        "NUM_CLASSES = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fevuVG2xqtlX"
      },
      "source": [
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import pipeline_pb2\n",
        "import os\n",
        "\n",
        "pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
        "config_path = PIPELINE_CONFIG_PATH\n",
        "with tf.gfile.GFile(config_path, \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline)\n",
        "\n",
        "pipeline.train_input_reader.tf_record_input_reader.input_path[:] = ['/content/dataset/train/Workers.tfrecord']\n",
        "pipeline.train_input_reader.label_map_path = '/content/dataset/train/Workers_label_map.pbtxt'\n",
        "pipeline.eval_input_reader[0].tf_record_input_reader.input_path[:] = ['/content/dataset/test/Workers.tfrecord']\n",
        "pipeline.eval_input_reader[0].label_map_path = '/content/dataset/test/Workers_label_map.pbtxt'\n",
        "pipeline.train_config.fine_tune_checkpoint = PIPELINE_CHECKPOINT_PATH\n",
        "pipeline.train_config.batch_size = BATCH_SIZE\n",
        "pipeline.train_config.num_steps = NUM_STEPS\n",
        "pipeline.model.ssd.num_classes = NUM_CLASSES\n",
        "# Enable ssdlite, this should already be enabled in the config we downloaded, but this is just to make sure.\n",
        "pipeline.model.ssd.box_predictor.convolutional_box_predictor.kernel_size = 3\n",
        "pipeline.model.ssd.box_predictor.convolutional_box_predictor.use_depthwise = True\n",
        "pipeline.model.ssd.feature_extractor.use_depthwise = True\n",
        "# Quantization Aware Training\n",
        "pipeline.graph_rewriter.quantization.delay = 0\n",
        "pipeline.graph_rewriter.quantization.weight_bits = 8\n",
        "pipeline.graph_rewriter.quantization.activation_bits = 8\n",
        "\n",
        "config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n",
        "with tf.gfile.Open(config_path, \"wb\") as f:                                                                                                                                                                                                                       \n",
        "    f.write(config_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1Mxqf9Ju5Ye",
        "outputId": "46c08669-60cf-4f47-8609-c57ca23665e2"
      },
      "source": [
        "! cat $PIPELINE_CONFIG_PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model {\n",
            "  ssd {\n",
            "    num_classes: 3\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 320\n",
            "        width: 320\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: \"ssd_mobiledet_edgetpu\"\n",
            "      depth_multiplier: 1.0\n",
            "      min_depth: 16\n",
            "      conv_hyperparams {\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 4e-05\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            mean: 0.0\n",
            "            stddev: 0.03\n",
            "          }\n",
            "        }\n",
            "        activation: RELU_6\n",
            "        batch_norm {\n",
            "          decay: 0.97\n",
            "          center: true\n",
            "          scale: true\n",
            "          epsilon: 0.001\n",
            "          train: true\n",
            "        }\n",
            "      }\n",
            "      use_depthwise: true\n",
            "      override_base_feature_extractor_hyperparams: false\n",
            "    }\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        conv_hyperparams {\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 4e-05\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              mean: 0.0\n",
            "              stddev: 0.03\n",
            "            }\n",
            "          }\n",
            "          activation: RELU_6\n",
            "          batch_norm {\n",
            "            decay: 0.97\n",
            "            center: true\n",
            "            scale: true\n",
            "            epsilon: 0.001\n",
            "            train: true\n",
            "          }\n",
            "        }\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 3\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        class_prediction_bias_init: -4.6\n",
            "        use_depthwise: true\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-08\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "        use_static_shapes: true\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    loss {\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "          delta: 1.0\n",
            "        }\n",
            "      }\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          gamma: 2.0\n",
            "          alpha: 0.75\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "  }\n",
            "}\n",
            "train_config {\n",
            "  batch_size: 32\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "  sync_replicas: true\n",
            "  optimizer {\n",
            "    momentum_optimizer {\n",
            "      learning_rate {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 0.8\n",
            "          total_steps: 400000\n",
            "          warmup_learning_rate: 0.13333\n",
            "          warmup_steps: 2000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/pretrained_model/ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19/fp32/model.ckpt\"\n",
            "  num_steps: 8000\n",
            "  startup_delay_steps: 0.0\n",
            "  replicas_to_aggregate: 32\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "}\n",
            "train_input_reader {\n",
            "  label_map_path: \"/content/dataset/train/Workers_label_map.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/dataset/train/Workers.tfrecord\"\n",
            "  }\n",
            "}\n",
            "eval_config {\n",
            "  num_examples: 8000\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "}\n",
            "eval_input_reader {\n",
            "  label_map_path: \"/content/dataset/test/Workers_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/dataset/test/Workers.tfrecord\"\n",
            "  }\n",
            "}\n",
            "graph_rewriter {\n",
            "  quantization {\n",
            "    delay: 0\n",
            "    weight_bits: 8\n",
            "    activation_bits: 8\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iB9BCsYvEOl"
      },
      "source": [
        "# **Launch tensorBoard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tljwzh1vvLKC",
        "outputId": "64cbfa50-4a2b-4466-d429-9ced8ccad5f3"
      },
      "source": [
        "%cd /content\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2021-07-07 06:33:13--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 3.232.43.226, 52.203.98.169, 52.45.2.162, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|3.232.43.226|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  17.7MB/s    in 0.7s    \n",
            "\n",
            "2021-07-07 06:33:14 (17.7 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsCGOjdFvR6r",
        "outputId": "01cbe452-0c14-4442-e2c8-11a6d7c6ff1b"
      },
      "source": [
        "# Starts tensorboard, so we can monitor the training process.\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format('/content/train')\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "print('Click this link to view training progress in TensorBoard:')\n",
        "import time\n",
        "time.sleep(1)\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Click this link to view training progress in TensorBoard:\n",
            "http://9a8f622988c7.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW3GZlStvYG6"
      },
      "source": [
        "# **Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsS7xcVwvde7"
      },
      "source": [
        "from datetime import datetime\n",
        "start = datetime.now()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFjap740viMJ",
        "outputId": "e409ab89-7b48-41b3-8061-2cebf981ec0a"
      },
      "source": [
        "%cd /content/models/research/\n",
        "! python3 object_detection/model_main.py \\\n",
        "    --logtostderr=true \\\n",
        "    --model_dir=/content/train \\\n",
        "    --pipeline_config_path=$PIPELINE_CONFIG_PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0707 06:33:21.257400 139850881451904 model_lib.py:817] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0707 06:33:21.257628 139850881451904 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0707 06:33:21.257725 139850881451904 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0707 06:33:21.257800 139850881451904 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0707 06:33:21.257872 139850881451904 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0707 06:33:21.257965 139850881451904 model_lib.py:833] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0707 06:33:21.258044 139850881451904 model_lib.py:870] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f31124010d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0707 06:33:21.258498 139850881451904 estimator.py:212] Using config: {'_model_dir': '/content/train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f31124010d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f3112424dd0>) includes params argument, but params are not passed to Estimator.\n",
            "W0707 06:33:21.258741 139850881451904 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f3112424dd0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0707 06:33:21.259201 139850881451904 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0707 06:33:21.259381 139850881451904 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0707 06:33:21.259590 139850881451904 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0707 06:33:21.269905 139850881451904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/dataset/train/Workers.tfrecord']\n",
            "I0707 06:33:21.295595 139850881451904 dataset_builder.py:163] Reading unweighted datasets: ['/content/dataset/train/Workers.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/dataset/train/Workers.tfrecord']\n",
            "I0707 06:33:21.296352 139850881451904 dataset_builder.py:80] Reading record datasets for input file: ['/content/dataset/train/Workers.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0707 06:33:21.296483 139850881451904 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0707 06:33:21.296545 139850881451904 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0707 06:33:21.302620 139850881451904 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0707 06:33:21.323506 139850881451904 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f3112401e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0707 06:33:21.362314 139850881451904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f3112401e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f311241e320> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0707 06:33:21.570847 139850881451904 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f311241e320> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:111: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0707 06:33:21.572809 139850881451904 deprecation.py:323] From /content/models/research/object_detection/inputs.py:111: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0707 06:33:21.581126 139850881451904 deprecation.py:323] From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:200: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0707 06:33:21.695489 139850881451904 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:200: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0707 06:33:22.533753 139850881451904 deprecation.py:323] From /content/models/research/object_detection/inputs.py:284: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0707 06:33:23.013972 139850881451904 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0707 06:33:23.029802 139850881451904 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0707 06:33:26.012152 139850881451904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0707 06:33:26.119349 139850881451904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0707 06:33:26.217819 139850881451904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0707 06:33:26.321373 139850881451904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0707 06:33:26.418858 139850881451904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0707 06:33:26.517506 139850881451904 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0707 06:33:56.620602 139850881451904 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0707 06:33:56.622259 139850881451904 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0707 06:34:02.656227 139850881451904 monitored_session.py:240] Graph was finalized.\n",
            "2021-07-07 06:34:02.656654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2021-07-07 06:34:02.661567: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1999995000 Hz\n",
            "2021-07-07 06:34:02.661826: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558d0a8f2000 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-07 06:34:02.661866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-07-07 06:34:02.664019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-07 06:34:02.675627: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-07-07 06:34:02.675689: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d415fb3d7327): /proc/driver/nvidia/version does not exist\n",
            "INFO:tensorflow:Restoring parameters from /content/train/model.ckpt-1\n",
            "I0707 06:34:02.677591 139850881451904 saver.py:1284] Restoring parameters from /content/train/model.ckpt-1\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0707 06:34:05.583337 139850881451904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0707 06:34:07.504691 139850881451904 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0707 06:34:08.182399 139850881451904 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /content/train/model.ckpt.\n",
            "I0707 06:34:25.850695 139850881451904 basic_session_run_hooks.py:606] Saving checkpoints for 1 into /content/train/model.ckpt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzdAuvf_vmIZ"
      },
      "source": [
        "end = datetime.now()\n",
        "duration = end - start\n",
        "seconds_in_hour = 60 * 60\n",
        "hours, seconds = divmod(duration.seconds, seconds_in_hour)\n",
        "minutes = int(seconds / 60)\n",
        "print('TRAINING TIME:', str(hours) + ':' + str(minutes if minutes > 10 else '%02d' % minutes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob-jmMfuzqqF"
      },
      "source": [
        "# **Export the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsSe4nOqzu3G"
      },
      "source": [
        "! python3 /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "    --output_directory=/content/inference_graph \\\n",
        "    --trained_checkpoint_prefix=/content/train/model.ckpt-$NUM_STEPS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nMmsywLz3-a"
      },
      "source": [
        "# **Evaluate the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uB4ABfgz8dz"
      },
      "source": [
        "! mkdir /content/validate_img\n",
        "! cd /content/validate_img\n",
        "! wget https://live.staticflickr.com/7739/17600110122_d2e7bc55cc_n.jpg -O /content/validate_img/image_1.jpg\n",
        "! wget https://live.staticflickr.com/4274/34553881773_5731624345_n.jpg -O /content/validate_img/image_2.jpg\n",
        "! wget https://live.staticflickr.com/2085/2276914329_97bb3fa820_n.jpg -O /content/validate_img/image_3.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDO_PSlu4Jse"
      },
      "source": [
        "# Do a Quick Evaluation on the inference graph model.\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import defaultdict\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "%matplotlib inline\n",
        "\n",
        "# Initialize tf.Graph()\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile('/content/inference_graph/frozen_inference_graph.pb', 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "# Loads labels\n",
        "label_map = label_map_util.load_labelmap('/content/dataset/train/Workers_label_map.pbtxt')\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=2, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Run Inference and populates results in a dict.\n",
        "def run_inference(graph, image):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = [output.name for op in ops for output in op.outputs]\n",
        "      tensor_dict = {}\n",
        "      tensor_keys = ['num_detections', 'detection_boxes', 'detection_scores', 'detection_classes']\n",
        "      for key in tensor_keys:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
        "      \n",
        "      # Actual inference.\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "      output_dict = sess.run(tensor_dict, feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "  return output_dict\n",
        "\n",
        "test_image_path = [os.path.join('/content/validate_img', 'image_{}.jpg'.format(i)) for i in range(1, 3)]\n",
        "for image_path in test_image_path:\n",
        "  print('Evaluating:', image_path)\n",
        "  image = Image.open(image_path)\n",
        "  img_width, img_height = image.size\n",
        "  image_np = np.array(image.getdata()).reshape((img_height, img_width, 3)).astype(np.uint8)\n",
        "  # Run inference.\n",
        "  output_dict = run_inference(detection_graph, image_np)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpqiskZG4pHb"
      },
      "source": [
        "# **Convert to TFlite format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPRqxlXe53aG"
      },
      "source": [
        "OUTPUT_DIR = '/content/output_ssdlite_mobiledet_hard_hat'\n",
        "! mkdir $OUTPUT_DIR\n",
        "! cp /content/dataset/train/Workers_label_map.pbtxt $OUTPUT_DIR/labels.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTzWLyI_4srB"
      },
      "source": [
        "# Export this model to tflite_graph format\n",
        "%cd /content/models/research\n",
        "\n",
        "! python3 object_detection/export_tflite_ssd_graph.py \\\n",
        "  --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "  --trained_checkpoint_prefix=/content/train/model.ckpt-$NUM_STEPS \\\n",
        "  --output_directory=$OUTPUT_DIR \\\n",
        "  --add_postprocessing_op=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMO2D2C648Qp"
      },
      "source": [
        "# Convert to a tflite file (for CPU)\n",
        "! tflite_convert \\\n",
        "  --output_file=\"$OUTPUT_DIR/ssdlite_mobiledet_hard_hat.tflite\" \\\n",
        "  --graph_def_file=\"$OUTPUT_DIR/tflite_graph.pb\" \\\n",
        "  --inference_type=QUANTIZED_UINT8 \\\n",
        "  --input_arrays=\"normalized_input_image_tensor\" \\\n",
        "  --output_arrays=\"TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3\" \\\n",
        "  --mean_values=128 \\\n",
        "  --std_dev_values=128 \\\n",
        "  --input_shapes=1,320,320,3 \\\n",
        "  --allow_custom_ops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op6NbNLD5M62"
      },
      "source": [
        "# **Evaluate the TFlite model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVZpFaPt5SA_"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "%matplotlib inline\n",
        "\n",
        "# Creates tflite interpreter\n",
        "interpreter = tf.lite.Interpreter(OUTPUT_DIR + '/ssdlite_mobiledet_hard_hat.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "interpreter.invoke() # warmup\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "width = input_details[0]['shape'][2]\n",
        "height = input_details[0]['shape'][1]\n",
        "\n",
        "def read_label_file(file_path):\n",
        "  with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "  ret = {}\n",
        "  for row_number, content in enumerate(lines):\n",
        "    pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\n",
        "    if len(pair) == 2 and pair[0].strip().isdigit():\n",
        "      ret[int(pair[0])] = pair[1].strip()\n",
        "    else:\n",
        "      ret[row_number] = content.strip()\n",
        "  return ret\n",
        "\n",
        "def run_inference(interpreter, image):\n",
        "  interpreter.set_tensor(input_details[0]['index'], image)\n",
        "  interpreter.invoke()\n",
        "  boxes = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "  classes = interpreter.get_tensor(output_details[1]['index'])[0]\n",
        "  scores = interpreter.get_tensor(output_details[2]['index'])[0]\n",
        "  # num_detections = interpreter.get_tensor(output_details[3]['index'])[0]\n",
        "  return boxes, classes, scores\n",
        "\n",
        "test_image_paths = [os.path.join('/content/validate_img', 'image_{}.jpg'.format(i)) for i in range(1, 3)]\n",
        "for image_path in test_image_paths:\n",
        "  print('Evaluating:', image_path)\n",
        "  image = Image.open(image_path)\n",
        "  image_width, image_height = image.size\n",
        "  draw = ImageDraw.Draw(image)\n",
        "  resized_image = image.resize((width, height))\n",
        "  np_image = np.asarray(resized_image)\n",
        "  input_tensor = np.expand_dims(np_image, axis=0)\n",
        "  # Run inference\n",
        "  boxes, classes, scores = run_inference(interpreter, input_tensor)\n",
        "  # Draw results on image\n",
        "  colors = {0:(128, 255, 102), 1:(102, 255, 255)}\n",
        "  labels = read_label_file(OUTPUT_DIR + '/labels.txt')\n",
        "  for i in range(len(boxes)):\n",
        "    if scores[i] > .7:\n",
        "      ymin = int(max(1, (boxes[i][0] * image_height)))\n",
        "      xmin = int(max(1, (boxes[i][1] * image_width)))\n",
        "      ymax = int(min(image_height, (boxes[i][2] * image_height)))\n",
        "      xmax = int(min(image_width, (boxes[i][3] * image_width)))\n",
        "      draw.rectangle((xmin, ymin, xmax, ymax), width=7, outline=colors[int(classes[i])])\n",
        "      draw.rectangle((xmin, ymin, xmax, ymin-10), fill=colors[int(classes[i])])\n",
        "      text = labels[int(classes[i])] + ' ' + str(scores[i]*100) + '%'\n",
        "      draw.text((xmin+2, ymin-10), text, fill=(0,0,0), width=2)\n",
        "  display(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gISh1zQI8lvf"
      },
      "source": [
        "# **Compile it for Edge TPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUy2l-pJFUfV"
      },
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "! sudo apt-get update\n",
        "! sudo apt-get install edgetpu-compiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPxdX3KQ8vL1"
      },
      "source": [
        "%cd $OUTPUT_DIR\n",
        "\n",
        "! edgetpu_compiler -s ssdlite_mobiledet_hard_hat.tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czYU5suZEkkP"
      },
      "source": [
        "# **Package and download all files(Optional)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYTfJuyYEmwD"
      },
      "source": [
        "! cp -r /content/train/model.ckpt-$NUM_STEPS* $OUTPUT_DIR\n",
        "! cp -r /content/inference_graph/* $OUTPUT_DIR\n",
        "\n",
        "%cd /content/\n",
        "! tar cvf output_ssdlite_mobiledet_hard_hat.tar.gz output_ssdlite_mobiledet_hard_hat\n",
        "\n",
        "#files.download('/content/output_ssdlite_mobiledet_hard_hat.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}