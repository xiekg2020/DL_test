{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "helmet_detection2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/uoq7EAGOSJ1jqKamKjEj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiekg2020/DL_test/blob/main/helmet_detection2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U4mx45n-vB1"
      },
      "source": [
        "# **Build TF2 object detection API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nrDtecd8tRH"
      },
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNxC3xLy80mu",
        "outputId": "0358ef48-6096-44e3-9dbd-54e5924f6e54"
      },
      "source": [
        "! pip install tf_slim\n",
        "! git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 59426, done.\u001b[K\n",
            "remote: Counting objects: 100% (905/905), done.\u001b[K\n",
            "remote: Compressing objects: 100% (338/338), done.\u001b[K\n",
            "remote: Total 59426 (delta 602), reused 828 (delta 550), pack-reused 58521\u001b[K\n",
            "Receiving objects: 100% (59426/59426), 573.69 MiB | 12.81 MiB/s, done.\n",
            "Resolving deltas: 100% (41229/41229), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYjpb3KC81U9"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/'\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/slim/'\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/object_detection/utils/'\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/object_detection'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFKSrCsw82d1",
        "outputId": "c17f2832-ef9d-4b49-e457-d626f5e39abb"
      },
      "source": [
        "! apt-get install protobuf-compiler"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9p5_G5w88Wk",
        "outputId": "de179685-d425-4da4-cce6-6147a62b5742"
      },
      "source": [
        "%cd models/research\n",
        "# Compile all the protobuf dependencies\n",
        "! protoc object_detection/protos/*.proto --python_out=.\n",
        "# Set up and install the object detection API\n",
        "! cp object_detection/packages/tf2/setup.py .\n",
        "! python -m pip install .\n",
        "# Run a test to make sure setup is correct\n",
        "! python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.31.0-cp37-cp37m-manylinux2010_x86_64.whl (9.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7 MB 13.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Requirement already satisfied: google-cloud-bigquery==1.21.0 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.21.0)\n",
            "Collecting tf-models-official\n",
            "  Downloading tf_models_official-2.5.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery==1.21.0->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery==1.21.0->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery==1.21.0->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (57.2.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (1.32.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.34.1)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 18.6 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery==1.21.0->object-detection==0.1) (2.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n",
            "\u001b[K     |████████████████████████████████| 679 kB 46.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 48 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 12.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, future, py-cpuinfo, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1660323 sha256=ffda7500b33c841c9eaa9bbfd6bd5f9640bc1fcd3ba23226e55eb96a48bb06c1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3lb8e2d7/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=507033b14172ba441f82b73c0a4454b66a27b63f488e13772a92271eb5f4f40b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=0a467d1770c41af0dd9871723cebbcb0dd84812a1e93d473cdbd4f5a508943f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=09df053f52f3684d4c3a025baf26b845a7f260d08954b2f0fceb8cf62177fdcb\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=2d9dcc3ad4666d2dd48cef2e43080d2f6054fa27741163c4f40be5776ca8390a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=5f9097931591d1e1db68df096ff6454d35a3083bdfc58265ae80c6dc93924151\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection avro-python3 dill future py-cpuinfo seqeval\n",
            "Installing collected packages: requests, portalocker, future, dill, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.31.0 avro-python3-1.9.2.1 dill-0.3.1.1 fastavro-1.4.4 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-1.5.1 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.13.0 tensorflow-model-optimization-0.6.0 tf-models-official-2.5.1\n",
            "2021-07-29 07:35:19.410032: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Running tests under Python 3.7.11: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2021-07-29 07:35:22.075139: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-29 07:35:22.137063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:35:22.137715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 07:35:22.137775: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 07:35:22.304417: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-29 07:35:22.304560: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-29 07:35:22.448823: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-29 07:35:22.495844: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-29 07:35:22.741524: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-29 07:35:22.799838: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-29 07:35:22.803855: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-29 07:35:22.804005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:35:22.804657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:35:22.810063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 07:35:22.810569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-29 07:35:22.810821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:35:22.811597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 07:35:22.811700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:35:22.812299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:35:22.815917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 07:35:22.818306: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 07:35:27.797902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 07:35:27.797956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-29 07:35:27.797975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-29 07:35:27.798156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:35:27.798790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:35:27.799367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:35:27.799886: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-29 07:35:27.799931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0729 07:35:28.039285 140325854074752 model_builder.py:1088] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 6.21s\n",
            "I0729 07:35:28.271202 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 6.21s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.54s\n",
            "I0729 07:35:28.808135 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.54s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n",
            "I0729 07:35:29.098368 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
            "I0729 07:35:29.346639 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "W0729 07:35:29.348859 140325854074752 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.84s\n",
            "I0729 07:35:31.182650 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.84s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0729 07:35:31.183742 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0729 07:35:31.204927 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0729 07:35:31.219832 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0729 07:35:31.238220 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I0729 07:35:31.330905 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "I0729 07:35:31.416374 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "I0729 07:35:31.516313 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0729 07:35:31.609231 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I0729 07:35:31.697524 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "I0729 07:35:31.722594 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0729 07:35:31.888413 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0729 07:35:31.888586 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0729 07:35:31.888664 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0729 07:35:31.890718 140325854074752 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0729 07:35:31.906584 140325854074752 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0729 07:35:31.906778 140325854074752 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0729 07:35:31.961762 140325854074752 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0729 07:35:31.961936 140325854074752 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0729 07:35:32.093947 140325854074752 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0729 07:35:32.094121 140325854074752 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0729 07:35:32.230321 140325854074752 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0729 07:35:32.230505 140325854074752 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0729 07:35:32.546810 140325854074752 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0729 07:35:32.546993 140325854074752 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0729 07:35:32.737874 140325854074752 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0729 07:35:32.738041 140325854074752 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0729 07:35:32.999264 140325854074752 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0729 07:35:32.999475 140325854074752 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0729 07:35:33.061459 140325854074752 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0729 07:35:33.086608 140325854074752 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0729 07:35:33.134034 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0729 07:35:33.134224 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0729 07:35:33.134299 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0729 07:35:33.135932 140325854074752 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0729 07:35:33.150940 140325854074752 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0729 07:35:33.151086 140325854074752 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0729 07:35:33.255213 140325854074752 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0729 07:35:33.255416 140325854074752 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0729 07:35:33.450807 140325854074752 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0729 07:35:33.450980 140325854074752 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0729 07:35:33.647750 140325854074752 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0729 07:35:33.647936 140325854074752 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0729 07:35:33.904109 140325854074752 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0729 07:35:33.904284 140325854074752 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0729 07:35:34.175161 140325854074752 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0729 07:35:34.175339 140325854074752 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0729 07:35:34.513679 140325854074752 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0729 07:35:34.513881 140325854074752 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0729 07:35:34.650024 140325854074752 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0729 07:35:34.676572 140325854074752 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0729 07:35:34.735491 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0729 07:35:34.735668 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0729 07:35:34.735751 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0729 07:35:34.737334 140325854074752 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0729 07:35:34.750875 140325854074752 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0729 07:35:34.751009 140325854074752 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0729 07:35:34.855549 140325854074752 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0729 07:35:34.855747 140325854074752 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0729 07:35:35.187301 140325854074752 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0729 07:35:35.187497 140325854074752 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0729 07:35:35.388427 140325854074752 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0729 07:35:35.388603 140325854074752 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0729 07:35:35.654072 140325854074752 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0729 07:35:35.654253 140325854074752 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0729 07:35:35.915188 140325854074752 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0729 07:35:35.915368 140325854074752 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0729 07:35:36.249157 140325854074752 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0729 07:35:36.249331 140325854074752 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0729 07:35:36.376564 140325854074752 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0729 07:35:36.401959 140325854074752 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0729 07:35:36.458138 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0729 07:35:36.458309 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0729 07:35:36.458387 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0729 07:35:36.459910 140325854074752 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0729 07:35:36.473373 140325854074752 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0729 07:35:36.473485 140325854074752 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0729 07:35:36.586874 140325854074752 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0729 07:35:36.587050 140325854074752 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0729 07:35:36.781356 140325854074752 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0729 07:35:36.781539 140325854074752 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0729 07:35:36.975583 140325854074752 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0729 07:35:36.975816 140325854074752 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0729 07:35:37.324984 140325854074752 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0729 07:35:37.325173 140325854074752 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0729 07:35:37.664133 140325854074752 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0729 07:35:37.664323 140325854074752 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0729 07:35:38.063406 140325854074752 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0729 07:35:38.063587 140325854074752 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0729 07:35:38.354974 140325854074752 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0729 07:35:38.381773 140325854074752 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0729 07:35:38.445245 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0729 07:35:38.445432 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0729 07:35:38.445506 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0729 07:35:38.447034 140325854074752 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0729 07:35:38.460723 140325854074752 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0729 07:35:38.460862 140325854074752 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0729 07:35:38.566576 140325854074752 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0729 07:35:38.566764 140325854074752 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0729 07:35:38.830959 140325854074752 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0729 07:35:38.831139 140325854074752 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0729 07:35:39.094613 140325854074752 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0729 07:35:39.094808 140325854074752 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0729 07:35:39.501153 140325854074752 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0729 07:35:39.501353 140325854074752 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0729 07:35:39.903531 140325854074752 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0729 07:35:39.903715 140325854074752 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0729 07:35:40.445657 140325854074752 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0729 07:35:40.445860 140325854074752 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0729 07:35:40.585814 140325854074752 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0729 07:35:40.611882 140325854074752 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0729 07:35:40.686671 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0729 07:35:40.686916 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0729 07:35:40.687000 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0729 07:35:40.688603 140325854074752 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0729 07:35:40.702299 140325854074752 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0729 07:35:40.702419 140325854074752 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0729 07:35:40.861908 140325854074752 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0729 07:35:40.862093 140325854074752 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0729 07:35:41.205964 140325854074752 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0729 07:35:41.206155 140325854074752 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0729 07:35:41.750963 140325854074752 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0729 07:35:41.751157 140325854074752 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0729 07:35:42.228071 140325854074752 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0729 07:35:42.228256 140325854074752 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0729 07:35:42.692566 140325854074752 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0729 07:35:42.692769 140325854074752 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0729 07:35:43.296099 140325854074752 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0729 07:35:43.296277 140325854074752 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0729 07:35:43.502979 140325854074752 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0729 07:35:43.539294 140325854074752 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0729 07:35:43.628800 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0729 07:35:43.628963 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0729 07:35:43.629031 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0729 07:35:43.630693 140325854074752 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0729 07:35:43.645709 140325854074752 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0729 07:35:43.645878 140325854074752 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0729 07:35:43.810277 140325854074752 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0729 07:35:43.810501 140325854074752 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0729 07:35:44.256707 140325854074752 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0729 07:35:44.256910 140325854074752 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0729 07:35:44.654579 140325854074752 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0729 07:35:44.654792 140325854074752 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0729 07:35:45.182794 140325854074752 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0729 07:35:45.182970 140325854074752 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0729 07:35:45.900937 140325854074752 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0729 07:35:45.901117 140325854074752 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0729 07:35:46.635486 140325854074752 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0729 07:35:46.635687 140325854074752 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0729 07:35:46.835599 140325854074752 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0729 07:35:46.863621 140325854074752 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0729 07:35:46.962790 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0729 07:35:46.962967 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0729 07:35:46.963037 140325854074752 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0729 07:35:46.964704 140325854074752 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0729 07:35:46.979143 140325854074752 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0729 07:35:46.979326 140325854074752 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0729 07:35:47.216310 140325854074752 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0729 07:35:47.216546 140325854074752 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0729 07:35:47.702007 140325854074752 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0729 07:35:47.702193 140325854074752 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0729 07:35:48.173384 140325854074752 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0729 07:35:48.173559 140325854074752 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0729 07:35:48.832545 140325854074752 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0729 07:35:48.832722 140325854074752 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0729 07:35:49.724353 140325854074752 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0729 07:35:49.724531 140325854074752 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0729 07:35:50.588303 140325854074752 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0729 07:35:50.588498 140325854074752 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0729 07:35:50.862443 140325854074752 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0729 07:35:50.900699 140325854074752 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.29s\n",
            "I0729 07:35:51.017742 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0729 07:35:51.024797 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0729 07:35:51.026642 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0729 07:35:51.027173 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0729 07:35:51.028712 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0729 07:35:51.030045 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0729 07:35:51.030470 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0729 07:35:51.031443 140325854074752 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 28.971s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDZ9h05M-3RS"
      },
      "source": [
        "# **Prepare dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5gSqNIH9VJa",
        "outputId": "e04faa04-4efd-4aeb-8e04-cd26557f6cb2"
      },
      "source": [
        "%mkdir /content/dataset\n",
        "%cd /content/dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwivdSlH-9XL",
        "outputId": "15374868-dfd7-4cac-c847-19d71b8505c2"
      },
      "source": [
        "!wget -O Hard_Hat_Workers.v2-raw.tfrecord.zip https://public.roboflow.com/ds/VUqgNE4eF7?key=jWeiF3tUqx"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-29 07:35:52--  https://public.roboflow.com/ds/VUqgNE4eF7?key=jWeiF3tUqx\n",
            "Resolving public.roboflow.com (public.roboflow.com)... 151.101.1.195, 151.101.65.195\n",
            "Connecting to public.roboflow.com (public.roboflow.com)|151.101.1.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/roboflow-platform-exports/Ly2DeBzbwsemGd2ReHk4BFxy8683/TlE7G4GXJk3kU7ivmTPR/2/tfrecord.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=roboflow-platform%40appspot.gserviceaccount.com%2F20210729%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210729T073552Z&X-Goog-Expires=901&X-Goog-SignedHeaders=host&X-Goog-Signature=1215527ceaa16aaf45c4dea1c30eaba2558deb0a6b1097d812ff0013ffb785115820eeaa50a039c210b0d593bc7df59e7766bb0e5ed6c4bf66f7351031be7f325e02cdc416818530e9bd77df3b3ac00508560cf6893769733fe223f8dedb969348a8e767a01ac7a0a55bce55f33871def7752eab19c2952295d1c2aa3ec6a2f17c5e34fa9a89790a0706390a97f14409a3275f254b1006943b255afb9c64d1fb6d7c8d89883c8bbb40915ba67485c6b1f084ca4f8a0b1ff645699e9ee553b1ebb6bdede4bdfd8d547fec847124224a75e92732d104a28bf871c869b247a4f1d3808813571595050c646e554eb50961b0bfb4c5a7fb312aab68fa3da5694fcaa2 [following]\n",
            "--2021-07-29 07:35:52--  https://storage.googleapis.com/roboflow-platform-exports/Ly2DeBzbwsemGd2ReHk4BFxy8683/TlE7G4GXJk3kU7ivmTPR/2/tfrecord.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=roboflow-platform%40appspot.gserviceaccount.com%2F20210729%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210729T073552Z&X-Goog-Expires=901&X-Goog-SignedHeaders=host&X-Goog-Signature=1215527ceaa16aaf45c4dea1c30eaba2558deb0a6b1097d812ff0013ffb785115820eeaa50a039c210b0d593bc7df59e7766bb0e5ed6c4bf66f7351031be7f325e02cdc416818530e9bd77df3b3ac00508560cf6893769733fe223f8dedb969348a8e767a01ac7a0a55bce55f33871def7752eab19c2952295d1c2aa3ec6a2f17c5e34fa9a89790a0706390a97f14409a3275f254b1006943b255afb9c64d1fb6d7c8d89883c8bbb40915ba67485c6b1f084ca4f8a0b1ff645699e9ee553b1ebb6bdede4bdfd8d547fec847124224a75e92732d104a28bf871c869b247a4f1d3808813571595050c646e554eb50961b0bfb4c5a7fb312aab68fa3da5694fcaa2\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.128, 142.250.141.128, 2607:f8b0:4023:c0b::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 244284985 (233M) [application/zip]\n",
            "Saving to: ‘Hard_Hat_Workers.v2-raw.tfrecord.zip’\n",
            "\n",
            "Hard_Hat_Workers.v2 100%[===================>] 232.97M   122MB/s    in 1.9s    \n",
            "\n",
            "2021-07-29 07:35:55 (122 MB/s) - ‘Hard_Hat_Workers.v2-raw.tfrecord.zip’ saved [244284985/244284985]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4S5Lzvv_B89",
        "outputId": "e887082d-c750-40b9-aacb-f1ed8adc8458"
      },
      "source": [
        "!unzip -o Hard_Hat_Workers.v2-raw.tfrecord.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Hard_Hat_Workers.v2-raw.tfrecord.zip\n",
            " extracting: test/Workers.tfrecord   \n",
            " extracting: train/Workers.tfrecord  \n",
            " extracting: test/Workers_label_map.pbtxt  \n",
            " extracting: train/Workers_label_map.pbtxt  \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: README.dataset.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTIqNXZy_GGM"
      },
      "source": [
        "# **Prepare model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWToxe1h_JFR",
        "outputId": "47693021-91e7-483d-e7c5-7c4256b8b62d"
      },
      "source": [
        "!mkdir /content/pretrained_model\n",
        "%cd /content/pretrained_model\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "!tar xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pretrained_model\n",
            "--2021-07-29 07:35:58--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.2.128, 2607:f8b0:4023:c0d::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.2.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 386527459 (369M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_resnet101_v1_fp 100%[===================>] 368.62M   138MB/s    in 2.7s    \n",
            "\n",
            "2021-07-29 07:36:01 (138 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n",
            "\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOv5MnZZ_v3u"
      },
      "source": [
        "PIPELINE_CONFIG_PATH = '/content/pretrained_model/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config'\n",
        "PIPELINE_CHECKPOINT_PATH = '/content/pretrained_model/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30PnBSr1FJfP"
      },
      "source": [
        "# Ideally, we'd use more steps, but much larger will reach the system timeout for a free Colab environment\n",
        "# If you have Colab Pro or you're running offline, try 25000\n",
        "NUM_STEPS = 2000\n",
        "\n",
        "# Ideally, batch size would be larger, but smaller is necessary to avoid OOM Killer on free Colab environments\n",
        "# If you have Colab Pro or you're running offline, try 64\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# For this tutorial, we're training just two classes\n",
        "# If you train with the whole cats/dogs dataset, it's 37 classes\n",
        "NUM_CLASSES = 3"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEbMyFE8FPJv"
      },
      "source": [
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import pipeline_pb2\n",
        "import os\n",
        "\n",
        "pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
        "config_path = PIPELINE_CONFIG_PATH\n",
        "with tf.io.gfile.GFile(config_path, \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline)\n",
        "\n",
        "pipeline.train_input_reader.tf_record_input_reader.input_path[:] = ['/content/dataset/train/Workers.tfrecord']\n",
        "pipeline.train_input_reader.label_map_path = '/content/dataset/train/Workers_label_map.pbtxt'\n",
        "pipeline.eval_input_reader[0].tf_record_input_reader.input_path[:] = ['/content/dataset/test/Workers.tfrecord']\n",
        "pipeline.eval_input_reader[0].label_map_path = '/content/dataset/test/Workers_label_map.pbtxt'\n",
        "pipeline.train_config.fine_tune_checkpoint = PIPELINE_CHECKPOINT_PATH\n",
        "pipeline.train_config.fine_tune_checkpoint_type = 'detection'\n",
        "pipeline.train_config.batch_size = BATCH_SIZE\n",
        "pipeline.train_config.num_steps = NUM_STEPS\n",
        "pipeline.model.ssd.num_classes = NUM_CLASSES\n",
        "\n",
        "config_text = text_format.MessageToBytes(pipeline)                                                                                                                                                                                                        \n",
        "with open(config_path, \"wb\") as f:                                                                                                                                                                                                                       \n",
        "    f.write(config_text)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJDNowlBGlG4",
        "outputId": "24d27808-b566-4abd-8070-610936a886f9"
      },
      "source": [
        "! cat $PIPELINE_CONFIG_PATH"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model {\n",
            "  ssd {\n",
            "    num_classes: 3\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 640\n",
            "        width: 640\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: \"ssd_resnet101_v1_fpn_keras\"\n",
            "      depth_multiplier: 1.0\n",
            "      min_depth: 16\n",
            "      conv_hyperparams {\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.0004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            mean: 0.0\n",
            "            stddev: 0.03\n",
            "          }\n",
            "        }\n",
            "        activation: RELU_6\n",
            "        batch_norm {\n",
            "          decay: 0.997\n",
            "          scale: true\n",
            "          epsilon: 0.001\n",
            "        }\n",
            "      }\n",
            "      override_base_feature_extractor_hyperparams: true\n",
            "      fpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "      }\n",
            "    }\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        conv_hyperparams {\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              mean: 0.0\n",
            "              stddev: 0.01\n",
            "            }\n",
            "          }\n",
            "          activation: RELU_6\n",
            "          batch_norm {\n",
            "            decay: 0.997\n",
            "            scale: true\n",
            "            epsilon: 0.001\n",
            "          }\n",
            "        }\n",
            "        depth: 256\n",
            "        num_layers_before_predictor: 4\n",
            "        kernel_size: 3\n",
            "        class_prediction_bias_init: -4.6\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        scales_per_octave: 2\n",
            "      }\n",
            "    }\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-08\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "        use_static_shapes: false\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    loss {\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          gamma: 2.0\n",
            "          alpha: 0.25\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "  }\n",
            "}\n",
            "train_config {\n",
            "  batch_size: 4\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_crop_image {\n",
            "      min_object_covered: 0.0\n",
            "      min_aspect_ratio: 0.75\n",
            "      max_aspect_ratio: 3.0\n",
            "      min_area: 0.75\n",
            "      max_area: 1.0\n",
            "      overlap_thresh: 0.0\n",
            "    }\n",
            "  }\n",
            "  sync_replicas: true\n",
            "  optimizer {\n",
            "    momentum_optimizer {\n",
            "      learning_rate {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 0.04\n",
            "          total_steps: 25000\n",
            "          warmup_learning_rate: 0.013333\n",
            "          warmup_steps: 2000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/pretrained_model/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
            "  num_steps: 2000\n",
            "  startup_delay_steps: 0.0\n",
            "  replicas_to_aggregate: 8\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  use_bfloat16: true\n",
            "  fine_tune_checkpoint_version: V2\n",
            "}\n",
            "train_input_reader {\n",
            "  label_map_path: \"/content/dataset/train/Workers_label_map.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/dataset/train/Workers.tfrecord\"\n",
            "  }\n",
            "}\n",
            "eval_config {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "}\n",
            "eval_input_reader {\n",
            "  label_map_path: \"/content/dataset/test/Workers_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/dataset/test/Workers.tfrecord\"\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zcLIEgBQQ2r"
      },
      "source": [
        "# **Luanch tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm1hAi2QQY9k",
        "outputId": "27518db2-4589-46f9-8ebc-ab8ef7524be9"
      },
      "source": [
        "%cd /content\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2021-07-29 07:49:37--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.55.225.227, 3.210.84.123, 52.4.80.235, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.55.225.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  18.1MB/s    in 0.7s    \n",
            "\n",
            "2021-07-29 07:49:38 (18.1 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0sDOLYVQcUo",
        "outputId": "3c2f3511-ff70-449e-82c7-0901f710ae28"
      },
      "source": [
        "# Starts tensorboard, so we can monitor the training process.\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format('/content/train')\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "print('Click this link to view training progress in TensorBoard:')\n",
        "import time\n",
        "time.sleep(1)\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Click this link to view training progress in TensorBoard:\n",
            "http://9f61f60fa7c4.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln8JqCQiQf6l"
      },
      "source": [
        "# **Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmVXGKSuQigb"
      },
      "source": [
        "from datetime import datetime\n",
        "start = datetime.now()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiP5IubKQlDD",
        "outputId": "6b6008fe-36a0-4eda-814c-1b26f52a759a"
      },
      "source": [
        "%cd /content/models/research/\n",
        "! python3 object_detection/model_main_tf2.py \\\n",
        "    --logtostderr=true \\\n",
        "    --model_dir=/content/train \\\n",
        "    --pipeline_config_path=$PIPELINE_CONFIG_PATH"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "2021-07-29 07:49:44.590320: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 07:49:48.340893: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-29 07:49:48.378779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:49:48.379448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 07:49:48.379502: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 07:49:48.385393: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-29 07:49:48.385506: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-29 07:49:48.391370: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-29 07:49:48.391820: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-29 07:49:48.394115: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-29 07:49:48.394978: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-29 07:49:48.395168: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-29 07:49:48.395283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:49:48.395979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:49:48.396576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 07:49:48.397011: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-29 07:49:48.397245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:49:48.398203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 07:49:48.398332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:49:48.399200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:49:48.400091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 07:49:48.400179: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 07:49:49.002281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 07:49:49.002338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-29 07:49:49.002359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-29 07:49:49.002585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:49:49.003486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:49:49.004319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 07:49:49.005079: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-29 07:49:49.005138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "W0729 07:49:49.007591 139677627901824 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0729 07:49:49.011306 139677627901824 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0729 07:49:49.016702 139677627901824 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0729 07:49:49.016853 139677627901824 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0729 07:49:49.036715 139677627901824 deprecation.py:336] From /content/models/research/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/dataset/train/Workers.tfrecord']\n",
            "I0729 07:49:49.062544 139677627901824 dataset_builder.py:163] Reading unweighted datasets: ['/content/dataset/train/Workers.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/dataset/train/Workers.tfrecord']\n",
            "I0729 07:49:49.062782 139677627901824 dataset_builder.py:80] Reading record datasets for input file: ['/content/dataset/train/Workers.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0729 07:49:49.062897 139677627901824 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0729 07:49:49.062981 139677627901824 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0729 07:49:49.071693 139677627901824 deprecation.py:336] From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0729 07:49:49.098256 139677627901824 deprecation.py:336] From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0729 07:49:56.963308 139677627901824 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0729 07:50:00.351587 139677627901824 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0729 07:50:02.182400 139677627901824 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-07-29 07:50:04.653710: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-07-29 07:50:04.659825: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000110000 Hz\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "2021-07-29 07:50:29.767393: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-29 07:50:31.961957: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004\n",
            "2021-07-29 07:50:56.333226: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-29 07:50:58.817929: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.843121 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.844420 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.846710 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.847596 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.849554 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.850376 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.852663 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.853509 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.855085 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0729 07:51:10.855904 139677627901824 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0729 07:51:12.153705 139674053699328 deprecation.py:534] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 1.173s\n",
            "I0729 07:53:08.994220 139677627901824 model_lib_v2.py:700] Step 100 per-step time 1.173s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.6760648,\n",
            " 'Loss/localization_loss': 0.6148561,\n",
            " 'Loss/regularization_loss': 2.4574423,\n",
            " 'Loss/total_loss': 4.7483635,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0729 07:53:08.994668 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 1.6760648,\n",
            " 'Loss/localization_loss': 0.6148561,\n",
            " 'Loss/regularization_loss': 2.4574423,\n",
            " 'Loss/total_loss': 4.7483635,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 0.728s\n",
            "I0729 07:54:21.777762 139677627901824 model_lib_v2.py:700] Step 200 per-step time 0.728s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.83316994,\n",
            " 'Loss/localization_loss': 0.69537675,\n",
            " 'Loss/regularization_loss': 2.4316216,\n",
            " 'Loss/total_loss': 3.9601684,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0729 07:54:21.778151 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.83316994,\n",
            " 'Loss/localization_loss': 0.69537675,\n",
            " 'Loss/regularization_loss': 2.4316216,\n",
            " 'Loss/total_loss': 3.9601684,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 0.742s\n",
            "I0729 07:55:36.021395 139677627901824 model_lib_v2.py:700] Step 300 per-step time 0.742s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7686228,\n",
            " 'Loss/localization_loss': 0.5289554,\n",
            " 'Loss/regularization_loss': 2.4000843,\n",
            " 'Loss/total_loss': 3.6976626,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0729 07:55:36.021718 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.7686228,\n",
            " 'Loss/localization_loss': 0.5289554,\n",
            " 'Loss/regularization_loss': 2.4000843,\n",
            " 'Loss/total_loss': 3.6976626,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 0.754s\n",
            "I0729 07:56:51.471915 139677627901824 model_lib_v2.py:700] Step 400 per-step time 0.754s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.99343497,\n",
            " 'Loss/localization_loss': 0.48248026,\n",
            " 'Loss/regularization_loss': 2.3664386,\n",
            " 'Loss/total_loss': 3.8423538,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0729 07:56:51.472285 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.99343497,\n",
            " 'Loss/localization_loss': 0.48248026,\n",
            " 'Loss/regularization_loss': 2.3664386,\n",
            " 'Loss/total_loss': 3.8423538,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 0.758s\n",
            "I0729 07:58:07.264660 139677627901824 model_lib_v2.py:700] Step 500 per-step time 0.758s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.62842077,\n",
            " 'Loss/localization_loss': 0.46799457,\n",
            " 'Loss/regularization_loss': 2.3326755,\n",
            " 'Loss/total_loss': 3.429091,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0729 07:58:07.265028 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.62842077,\n",
            " 'Loss/localization_loss': 0.46799457,\n",
            " 'Loss/regularization_loss': 2.3326755,\n",
            " 'Loss/total_loss': 3.429091,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 0.757s\n",
            "I0729 07:59:22.939608 139677627901824 model_lib_v2.py:700] Step 600 per-step time 0.757s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.6466428,\n",
            " 'Loss/localization_loss': 0.54759145,\n",
            " 'Loss/regularization_loss': 2.2955725,\n",
            " 'Loss/total_loss': 3.489807,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0729 07:59:22.939942 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.6466428,\n",
            " 'Loss/localization_loss': 0.54759145,\n",
            " 'Loss/regularization_loss': 2.2955725,\n",
            " 'Loss/total_loss': 3.489807,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 0.757s\n",
            "I0729 08:00:38.683794 139677627901824 model_lib_v2.py:700] Step 700 per-step time 0.757s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.6309666,\n",
            " 'Loss/localization_loss': 0.4114943,\n",
            " 'Loss/regularization_loss': 2.2574396,\n",
            " 'Loss/total_loss': 3.2999005,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0729 08:00:38.684160 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.6309666,\n",
            " 'Loss/localization_loss': 0.4114943,\n",
            " 'Loss/regularization_loss': 2.2574396,\n",
            " 'Loss/total_loss': 3.2999005,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 0.757s\n",
            "I0729 08:01:54.429811 139677627901824 model_lib_v2.py:700] Step 800 per-step time 0.757s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.73001975,\n",
            " 'Loss/localization_loss': 0.50135016,\n",
            " 'Loss/regularization_loss': 2.2207153,\n",
            " 'Loss/total_loss': 3.4520853,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0729 08:01:54.430162 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.73001975,\n",
            " 'Loss/localization_loss': 0.50135016,\n",
            " 'Loss/regularization_loss': 2.2207153,\n",
            " 'Loss/total_loss': 3.4520853,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 0.758s\n",
            "I0729 08:03:10.197354 139677627901824 model_lib_v2.py:700] Step 900 per-step time 0.758s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 2.9927802,\n",
            " 'Loss/localization_loss': 0.7722331,\n",
            " 'Loss/regularization_loss': 2.179059,\n",
            " 'Loss/total_loss': 5.9440722,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0729 08:03:10.197682 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 2.9927802,\n",
            " 'Loss/localization_loss': 0.7722331,\n",
            " 'Loss/regularization_loss': 2.179059,\n",
            " 'Loss/total_loss': 5.9440722,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.758s\n",
            "I0729 08:04:25.965235 139677627901824 model_lib_v2.py:700] Step 1000 per-step time 0.758s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.6649983,\n",
            " 'Loss/localization_loss': 0.48510173,\n",
            " 'Loss/regularization_loss': 2.1405947,\n",
            " 'Loss/total_loss': 3.2906947,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0729 08:04:25.965600 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.6649983,\n",
            " 'Loss/localization_loss': 0.48510173,\n",
            " 'Loss/regularization_loss': 2.1405947,\n",
            " 'Loss/total_loss': 3.2906947,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.780s\n",
            "I0729 08:05:43.995308 139677627901824 model_lib_v2.py:700] Step 1100 per-step time 0.780s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.79829,\n",
            " 'Loss/localization_loss': 0.45201474,\n",
            " 'Loss/regularization_loss': 2.096183,\n",
            " 'Loss/total_loss': 3.3464878,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0729 08:05:43.995624 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.79829,\n",
            " 'Loss/localization_loss': 0.45201474,\n",
            " 'Loss/regularization_loss': 2.096183,\n",
            " 'Loss/total_loss': 3.3464878,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.756s\n",
            "I0729 08:06:59.620254 139677627901824 model_lib_v2.py:700] Step 1200 per-step time 0.756s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.68336153,\n",
            " 'Loss/localization_loss': 0.3720446,\n",
            " 'Loss/regularization_loss': 2.0510015,\n",
            " 'Loss/total_loss': 3.1064076,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0729 08:06:59.620632 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.68336153,\n",
            " 'Loss/localization_loss': 0.3720446,\n",
            " 'Loss/regularization_loss': 2.0510015,\n",
            " 'Loss/total_loss': 3.1064076,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.758s\n",
            "I0729 08:08:15.439162 139677627901824 model_lib_v2.py:700] Step 1300 per-step time 0.758s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.59066665,\n",
            " 'Loss/localization_loss': 0.4492285,\n",
            " 'Loss/regularization_loss': 2.005017,\n",
            " 'Loss/total_loss': 3.044912,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0729 08:08:15.439635 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.59066665,\n",
            " 'Loss/localization_loss': 0.4492285,\n",
            " 'Loss/regularization_loss': 2.005017,\n",
            " 'Loss/total_loss': 3.044912,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.757s\n",
            "I0729 08:09:31.182183 139677627901824 model_lib_v2.py:700] Step 1400 per-step time 0.757s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.3549597,\n",
            " 'Loss/localization_loss': 0.39227933,\n",
            " 'Loss/regularization_loss': 3.219038,\n",
            " 'Loss/total_loss': 4.9662766,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0729 08:09:31.182499 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 1.3549597,\n",
            " 'Loss/localization_loss': 0.39227933,\n",
            " 'Loss/regularization_loss': 3.219038,\n",
            " 'Loss/total_loss': 4.9662766,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.756s\n",
            "I0729 08:10:46.754113 139677627901824 model_lib_v2.py:700] Step 1500 per-step time 0.756s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.6239272,\n",
            " 'Loss/localization_loss': 0.65024936,\n",
            " 'Loss/regularization_loss': 15.360634,\n",
            " 'Loss/total_loss': 17.634811,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0729 08:10:46.754442 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 1.6239272,\n",
            " 'Loss/localization_loss': 0.65024936,\n",
            " 'Loss/regularization_loss': 15.360634,\n",
            " 'Loss/total_loss': 17.634811,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.750s\n",
            "I0729 08:12:01.796519 139677627901824 model_lib_v2.py:700] Step 1600 per-step time 0.750s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.76206505,\n",
            " 'Loss/localization_loss': 0.64396805,\n",
            " 'Loss/regularization_loss': 31.620024,\n",
            " 'Loss/total_loss': 33.026054,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0729 08:12:01.796887 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.76206505,\n",
            " 'Loss/localization_loss': 0.64396805,\n",
            " 'Loss/regularization_loss': 31.620024,\n",
            " 'Loss/total_loss': 33.026054,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.751s\n",
            "I0729 08:13:16.941344 139677627901824 model_lib_v2.py:700] Step 1700 per-step time 0.751s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7725003,\n",
            " 'Loss/localization_loss': 0.6305764,\n",
            " 'Loss/regularization_loss': 31.09328,\n",
            " 'Loss/total_loss': 32.496357,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0729 08:13:16.941704 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.7725003,\n",
            " 'Loss/localization_loss': 0.6305764,\n",
            " 'Loss/regularization_loss': 31.09328,\n",
            " 'Loss/total_loss': 32.496357,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.749s\n",
            "I0729 08:14:31.865338 139677627901824 model_lib_v2.py:700] Step 1800 per-step time 0.749s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7253372,\n",
            " 'Loss/localization_loss': 0.5356132,\n",
            " 'Loss/regularization_loss': 30.201189,\n",
            " 'Loss/total_loss': 31.462141,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0729 08:14:31.865687 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.7253372,\n",
            " 'Loss/localization_loss': 0.5356132,\n",
            " 'Loss/regularization_loss': 30.201189,\n",
            " 'Loss/total_loss': 31.462141,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.750s\n",
            "I0729 08:15:46.895310 139677627901824 model_lib_v2.py:700] Step 1900 per-step time 0.750s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.76453495,\n",
            " 'Loss/localization_loss': 0.54915446,\n",
            " 'Loss/regularization_loss': 29.309433,\n",
            " 'Loss/total_loss': 30.623121,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0729 08:15:46.895643 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.76453495,\n",
            " 'Loss/localization_loss': 0.54915446,\n",
            " 'Loss/regularization_loss': 29.309433,\n",
            " 'Loss/total_loss': 30.623121,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.750s\n",
            "I0729 08:17:01.890091 139677627901824 model_lib_v2.py:700] Step 2000 per-step time 0.750s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7014486,\n",
            " 'Loss/localization_loss': 0.5225819,\n",
            " 'Loss/regularization_loss': 28.430422,\n",
            " 'Loss/total_loss': 29.654451,\n",
            " 'learning_rate': 0.04}\n",
            "I0729 08:17:01.890429 139677627901824 model_lib_v2.py:701] {'Loss/classification_loss': 0.7014486,\n",
            " 'Loss/localization_loss': 0.5225819,\n",
            " 'Loss/regularization_loss': 28.430422,\n",
            " 'Loss/total_loss': 29.654451,\n",
            " 'learning_rate': 0.04}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hic8L3nQpcT",
        "outputId": "43710f18-8706-476f-f0c4-696665d3c0e8"
      },
      "source": [
        "end = datetime.now()\n",
        "duration = end - start\n",
        "seconds_in_hour = 60 * 60\n",
        "hours, seconds = divmod(duration.seconds, seconds_in_hour)\n",
        "minutes = int(seconds / 60)\n",
        "print('TRAINING TIME:', str(hours) + ':' + str(minutes if minutes > 10 else '%02d' % minutes))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING TIME: 0:27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rsKWVLas1bA"
      },
      "source": [
        "# **Export the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGz67cjms_7x",
        "outputId": "6e3bc63d-9b5e-471f-e0a9-1a223a18e291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! python3 /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n",
        "    --output_directory=/content/inference_graph \\\n",
        "    --trained_checkpoint_dir=/content/train"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-29 08:22:25.773250: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 08:22:27.616781: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-29 08:22:27.645192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:22:27.645862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:22:27.645908: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 08:22:27.648421: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-29 08:22:27.648499: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-29 08:22:27.650158: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-29 08:22:27.650503: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-29 08:22:27.652516: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-29 08:22:27.653230: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-29 08:22:27.653423: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-29 08:22:27.653522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:22:27.654113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:22:27.654656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 08:22:27.654952: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-29 08:22:27.655170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:22:27.655719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:22:27.655804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:22:27.656361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:22:27.656876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 08:22:27.656934: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 08:22:28.171022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 08:22:28.171079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-29 08:22:28.171097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-29 08:22:28.171295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:22:28.171955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:22:28.172523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:22:28.173099: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-29 08:22:28.173149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0729 08:22:28.316660 140328996382592 deprecation.py:601] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa0700cf190>, because it is not built.\n",
            "W0729 08:22:47.083773 140328996382592 save_impl.py:77] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa0700cf190>, because it is not built.\n",
            "2021-07-29 08:23:05.044445: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0729 08:23:35.194671 140328996382592 save.py:243] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n",
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "W0729 08:23:42.326715 140328996382592 save.py:1240] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: /content/inference_graph/saved_model/assets\n",
            "I0729 08:23:43.484668 140328996382592 builder_impl.py:775] Assets written to: /content/inference_graph/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/inference_graph/pipeline.config\n",
            "I0729 08:23:44.709638 140328996382592 config_util.py:254] Writing pipeline config file to /content/inference_graph/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3oKCHxvBdpt",
        "outputId": "b7c6bdae-17ea-4bad-e7d7-eef119394af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-3.8.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 38.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 30 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 51 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 61 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.34.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (57.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.26.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow<3,>=2.1.0->tensorflowjs) (3.5.0)\n",
            "Installing collected packages: tensorflowjs\n",
            "Successfully installed tensorflowjs-3.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MKsn7DjVvzM"
      },
      "source": [
        "OUTPUT_DIR = '/content/output_ssd_resnet101_v1_fpn_640x640_coco17_tpu-8_hard_hat'\n",
        "! mkdir $OUTPUT_DIR"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7M5kaaqWCAV",
        "outputId": "372b5de4-88a3-41fb-c2d1-ff534234479c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python3 object_detection/export_tflite_graph_tf2.py  \\\n",
        "--pipeline_config_path=/content/inference_graph/pipeline.config \\\n",
        "--trained_checkpoint_dir=/content/train \\\n",
        "--output_directory=/content/output_ssd_resnet101_v1_fpn_640x640_coco17_tpu-8_hard_hat"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-29 08:33:19.600093: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 08:33:21.519218: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-29 08:33:21.548418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:21.549064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:33:21.549106: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 08:33:21.552042: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-29 08:33:21.552134: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-29 08:33:21.554015: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-29 08:33:21.554389: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-29 08:33:21.556598: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-29 08:33:21.557262: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-29 08:33:21.557461: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-29 08:33:21.557572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:21.558213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:21.558825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 08:33:21.559151: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-07-29 08:33:21.559407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:21.560009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:33:21.560097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:21.560674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:21.561232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 08:33:21.561292: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-29 08:33:22.087823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 08:33:22.087878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-29 08:33:22.087893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-29 08:33:22.088076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:22.088691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:22.089276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:22.089802: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-29 08:33:22.089849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-07-29 08:33:31.290755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:31.291357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:33:31.291484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:31.292056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:31.292561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 08:33:31.292605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 08:33:31.292619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-29 08:33:31.292629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-29 08:33:31.292731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:31.293286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:31.293801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-07-29 08:33:31.329505: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000110000 Hz\n",
            "2021-07-29 08:33:33.372478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:33.373098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:33:33.373229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:33.373819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:33.374342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 08:33:33.374393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 08:33:33.374410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-29 08:33:33.374421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-29 08:33:33.374531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:33.375123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:33.375633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f0800389350>, because it is not built.\n",
            "W0729 08:33:34.202662 139674312107904 save_impl.py:77] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f0800389350>, because it is not built.\n",
            "2021-07-29 08:33:51.771078: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2021-07-29 08:33:53.855403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:53.856107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:33:53.856246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:53.856952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:53.857534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-29 08:33:53.857585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 08:33:53.857602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-29 08:33:53.857615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-29 08:33:53.857728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:53.858373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:33:53.858965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0729 08:34:22.052616 139674312107904 save.py:243] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n",
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "W0729 08:34:29.161185 139674312107904 save.py:1240] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
            "INFO:tensorflow:Assets written to: /content/output_ssd_resnet101_v1_fpn_640x640_coco17_tpu-8_hard_hat/saved_model/assets\n",
            "I0729 08:34:30.345920 139674312107904 builder_impl.py:775] Assets written to: /content/output_ssd_resnet101_v1_fpn_640x640_coco17_tpu-8_hard_hat/saved_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c0BihDjZhap",
        "outputId": "01147a06-f0ef-477f-835a-84a3a7eaa02c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!tflite_convert \\\n",
        "--saved_model_dir=/content/output_ssd_resnet101_v1_fpn_640x640_coco17_tpu-8_hard_hat/saved_model \\\n",
        "--output_file=/content/output_ssd_resnet101_v1_fpn_640x640_coco17_tpu-8_hard_hat/detect.tflite \\\n",
        "--input_shapes=1,640,640,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-29 08:38:04.849877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-29 08:38:04.887464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:04.888274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:38:04.893465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-29 08:38:05.160851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-07-29 08:38:05.163021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-29 08:38:05.163421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-29 08:38:05.165323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-29 08:38:05.188653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-07-29 08:38:05.697241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-29 08:38:05.697448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:05.698146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:05.698719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-07-29 08:38:05.699145: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2021-07-29 08:38:05.741601: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000110000 Hz\n",
            "2021-07-29 08:38:05.741915: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b639c5cbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-29 08:38:05.741954: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-07-29 08:38:05.854547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:05.855487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b639c5cd80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-29 08:38:05.855524: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-07-29 08:38:05.855850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:05.856477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:38:05.856537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-29 08:38:05.856559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-07-29 08:38:05.856580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-29 08:38:05.856599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-29 08:38:05.856619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-29 08:38:05.856637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-07-29 08:38:05.856656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-29 08:38:05.856763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:05.857403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:05.858002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-07-29 08:38:05.860885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-29 08:38:05.862230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 08:38:05.862263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2021-07-29 08:38:05.862277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2021-07-29 08:38:05.864623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:05.865263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:05.865888: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-29 08:38:05.865934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-07-29 08:38:29.832674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:29.833269: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2021-07-29 08:38:29.833374: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-07-29 08:38:29.834138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:29.834681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:38:29.834755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-29 08:38:29.834792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-07-29 08:38:29.834812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-29 08:38:29.834832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-29 08:38:29.834854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-29 08:38:29.834872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-07-29 08:38:29.834890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-29 08:38:29.834950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:29.835475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:29.835984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-07-29 08:38:29.836028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 08:38:29.836042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2021-07-29 08:38:29.836054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2021-07-29 08:38:29.836142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:29.836671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:29.837190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-07-29 08:38:29.960244: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\n",
            "2021-07-29 08:38:29.960300: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 3950 nodes (3211), 10120 edges (9378), time = 71.524ms.\n",
            "2021-07-29 08:38:29.960310: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 1.767ms.\n",
            "2021-07-29 08:38:34.478409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:34.479038: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2021-07-29 08:38:34.479162: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2021-07-29 08:38:34.479823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:34.480384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-29 08:38:34.480447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-07-29 08:38:34.480471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-07-29 08:38:34.480493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-29 08:38:34.480513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-29 08:38:34.480533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-29 08:38:34.480552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-07-29 08:38:34.480572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-29 08:38:34.480631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:34.481203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:34.481690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2021-07-29 08:38:34.481731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-29 08:38:34.481756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2021-07-29 08:38:34.481769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2021-07-29 08:38:34.481858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:34.482396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-29 08:38:34.482919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2021-07-29 08:38:36.819265: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize\n",
            "2021-07-29 08:38:36.819337: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1507 nodes (-738), 5339 edges (-1456), time = 1511.05103ms.\n",
            "2021-07-29 08:38:36.819347: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1507 nodes (0), 5339 edges (0), time = 526.978ms.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5OvnigvxIiE"
      },
      "source": [
        "# **Evaluate the trained model**"
      ]
    }
  ]
}